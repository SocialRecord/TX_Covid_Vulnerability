import numpy as np
import pandas as pd
import datetime


def acquire_people_data():
    '''
    Read in the People csv, filter to only Texas counties,
    drop unecessary columns, return dataframe
    '''
    df = pd.read_csv("./Data/People.csv")
    # Restrict df to only Texas
    df = df[df.State == "TX"]
    # Keep only the columns we want and set index to FIPS
    good_columns = [
        "FIPS",
        "LandAreaSQMiles2010",
        # Population estimates
        "TotalPopEst2018",
        "PopDensity2010",
        "Age65AndOlderNum2010",
        "Under18Num2010",
        "NaturalChange1018",
        # Household size
        "AvgHHSize",
        "TotalOccHU",
        "OwnHomeNum",
        # Head of Household
        "FemaleHHNum",
        "TotalHH",
        "NonEnglishHHNum",
        "HH65PlusAloneNum",
        # Education columns
        "Ed1LessThanHSNum",
        "Ed2HSDiplomaOnlyNum",
        "Ed3SomeCollegeNum",
        "Ed4AssocDegreeNum",
        "Ed5CollegePlusNum",
        # Race columns
        "WhiteNonHispanicNum2010",
        "BlackNonHispanicNum2010",
        "AsianNonHispanicNum2010",
        "NativeAmericanNonHispanicNum2010",
        "HispanicNum2010",
        "MultipleRaceNum2010",
    ]
    df = df[good_columns]
    return df


def acquire_veteran_data():
    '''
    Read in Veteran csv, filter to only Texas counties, 
    drop unecessary columns, return dataframe
    '''
    df = pd.read_csv("./Data/Veterans.csv")
    # Restrict df to only Texas
    df = df[df.State == "TX"]
    # Keep only the columns we want and set index to FIPS
    good_columns = [
        "FIPS",
        "State",
        # Income for both vets and non-vets
        "MedianVetsInc",
        "MedianNonVetsInc",
        # Number of vets 18 and over
        "Vets18ONum",
        # Number of vets in civilian labor force
        "CLFVets18to64Num",
        "NonVetsDisabilty",
        "VetsDisabilty",
        "NonVetsPoor",
        "VetsPoor",
    ]
    df = df[good_columns]
    return df


def acquire_covid_cases():
    """
    Takes in the case counts from the Dept. of State Health Services official website.
    This file was precleaned in Excel before importing into our notebook; 
    if you update this file you will need to do these precleaning steps:
    We deleted the original column names and turned them into actual dates, 
    added columns where they were missing data and filled them with zeros to have every day accounted for,
    deleted the counties reporting row, and deleted the notes and disclaimers.
    Creates a new df with each county, population, number of covid cases, and the pct of the population infected. 
    """
    df = pd.read_excel("./Data/Texas_COVID-19_Case_Count_Data_by_County.xlsx")
    # Keep only most recent covid data
    columns_to_keep = [
        "County Name",
        "Population",
        datetime.datetime(
            2020, 6, 18, 0, 0
        ),  # if this file gets updated, this column should be replaced with the most recent date
    ]
    df = df[columns_to_keep]
    # rename last column
    df = df.rename(
        columns={
            "County Name": "County",
            "Population": "population",
            datetime.datetime(2020, 6, 18, 0, 0): "num_covid_cases",
        }
    )
    # create infection rate column
    df["infection_pct"] = (df["num_covid_cases"] / df["population"]) * 100
    # drop nans
    df = df.dropna()

    # lowercase the County column
    df['County'] = df['County'].str.lower()



    return df

def acquire_texas_hospitals():
    '''
    Read in Hospital csv, filter to only Texas counties, 
    drop unecessary columns, return dataframe
    '''
    hospitals = pd.read_csv("./Data/Hospitals.csv")

    # create mask to filter for hospitals in TX
    mask = hospitals.STATE == "TX"
    tx_hospitals = hospitals[mask]

    # drop useless columns
    tx_hospitals = tx_hospitals.drop(
        columns=[
            "X",
            "Y",
            "FID",
            "ID",
            "ZIP4",
            "TELEPHONE",
            "POPULATION",
            "COUNTRY",
            "NAICS_CODE",
            "SOURCE",
            "SOURCEDATE",
            "VAL_METHOD",
            "VAL_DATE",
            "WEBSITE",
            "ALT_NAME",
            "TTL_STAFF",
            "BEDS",
            "TRAUMA",
            "HELIPAD",
        ]
    )

    # rename county_fips to fips
    tx_hospitals.rename(columns={"COUNTYFIPS": "FIPS"}, inplace=True)

    # drop the closed hospitlas
    mask = tx_hospitals.STATUS == "OPEN"
    tx_hospitals = tx_hospitals[mask]

    # Convert FIPS to int
    tx_hospitals = tx_hospitals.astype({"FIPS": "int"})

    return tx_hospitals


def get_texas_hospitals():
    """Uses hospitals csv and return just the open texas hospitals"""
    hospitals = pd.read_csv("./Data/Hospitals.csv")
    
    #create mask to filter for hospitals in TX
    mask = hospitals.STATE == "TX"
    tx_hospitals = hospitals[mask]
    
    #drop useless columns
    tx_hospitals = tx_hospitals.drop(columns = ["X", "Y", "FID", "ID", "ZIP4", "TELEPHONE", 
                            "POPULATION", "COUNTRY", "NAICS_CODE", "SOURCE", "SOURCEDATE",
                            "VAL_METHOD", "VAL_DATE", "WEBSITE", "ALT_NAME", "TTL_STAFF",
                            "BEDS", "TRAUMA", "HELIPAD"])
    
    #rename county_fips to fips
    tx_hospitals.rename(columns = {"COUNTYFIPS" : "FIPS"}, inplace = True)

    #drop the closed hospitlas
    mask = tx_hospitals.STATUS == "OPEN"
    tx_hospitals = tx_hospitals[mask]
    
    return tx_hospitals



def create_hospital_count_df():
    """
    Uses the get_texas_hospitals function and creates a dataframe
    totaling the number of hospitals homes per county
    """
    #Bring in the hospitals dataframe    
    hosp = get_texas_hospitals()
    
    #Get the value counts for each FIPS (county)
    df = pd.DataFrame(hosp.FIPS.value_counts()).reset_index()
    
    #Rename the columns
    df.rename(columns = {"FIPS": "num_hospitals"}, inplace = True)
    df.rename(columns = {"index": "FIPS"}, inplace = True)

    df['FIPS'] = df.FIPS.astype(int)
    
    return df




def acquire_income_data():
    '''
    Read in the Income csv, filter to only Texas counties,
    drop unecessary columns, return dataframe
    '''
    # Read in csv and set inded to FIPS
    df = pd.read_csv('./Data/Income.csv')

    # Create a boolean mask where only observations where TX is the state are counted as true
    # Then apply the mask to the whole dataframe
    mask = df['State'] == 'TX'
    df = df[mask]

    # Drop columns we don't need
    df = df.drop(
        columns = ['PerCapitaInc', 
        'PovertyUnder18Pct', 
        'PovertyAllAgesPct', 
        'Deep_Pov_Children',
        'State',])
    
    # Lowecase the county names
    df['County'] = df['County'].str.lower()

    return df

def acquire_food_data():
    '''
    Read in the Food1 excel file, filter to only Texas counties,
    drop unecessary columns, return dataframe
    '''

    # Pull in only the columns I want
    file_loc = "./Data/Food1.xlsx"
    df = pd.read_excel(file_loc, index_col='FIPS', na_values=['NA'], usecols = "A,B,E")

    # Restrict df to Texas only
    mask = df['State'] == 'TX'
    df = df[mask]

    # Drop the state column
    df = df.drop(columns = 'State')
    return df


def acquire_jobs_data():
    '''
    Read in the jobs csv, filter to only Texas counties,
    drop unecessary columns, return dataframe
    '''
    df = pd.read_csv("./Data/Jobs.csv")
    # Restrict df to only Texas
    df = df[df.State == "TX"]
    # Keep only the columns we want and set index to FIPS
    good_columns = ['FIPS',
        # unemployment rate in 2018
        'UnempRate2018',
        'NumUnemployed2018',
        'NumEmployed2018','NumCivLaborforce2018',
        # percentage of workforce in various working industries 
        'PctEmpAgriculture','PctEmpMining','PctEmpConstruction','PctEmpManufacturing',
        'PctEmpTrade','PctEmpTrans','PctEmpInformation','PctEmpFIRE','PctEmpServices','PctEmpGovt'
    ]
    df = df[good_columns]
    return df


def acquire_tx_county_class():
    """
    Read in the tx_county_class csv, filter to only Texas counties,
    drop unecessary columns, return dataframe
    """
    county_class = pd.read_csv("./Data/County Classifications.csv")
    
    # get only TX datapoints
    mask = county_class.State == "TX"
    tx_county_class = county_class[mask]
    
    #rename the FIPS column
    tx_county_class.rename(columns = {"FIPStxt" : "FIPS"}, inplace = True)
    
    columns_to_drop = ['RuralUrbanContinuumCode2003', 'UrbanInfluenceCode2003', 
                   'PersistentChildPoverty_1980_2011', 'Perpov_1980_0711',
                  'Hipov', 'Metro2003', 'NonmetroNotAdj2003', 'NonmetroAdj2003',
                   'Micropolitan2003', 'FarmDependent2003', 'ManufacturingDependent2000',
                   'LowEducation2000', 'RetirementDestination2000', 'PersistentPoverty2000',
                   'PersistentChildPoverty2004', 'RecreationDependent2000', 'Nonmetro2013',
                   'Gas_Change', 'Oil_Change', 'Type_2015_Nonspecialized_NO', 
                   'Low_Education_2015_update', 'HiCreativeClass2000', 'EconomicDependence2000',
                   'Nonmetro2003', 'Noncore2013', 'Oil_Gas_Change', 'Noncore2003',
                   'State', 'County', 'Type_2015_Update'      
                  ]
    
    #drop the columns
    tx_county_class = tx_county_class.drop(columns = columns_to_drop)
    
    return tx_county_class

def acquire_nh_data():
    '''
    Read in the NurstinFacilities excel file, filter to only Texas counties,
    drop unecessary columns, return dataframe
    '''
    df = pd.read_excel("./Data/NursingFacilities.xlsx", header=1)
    # Keep only relevant columns
    columns_to_keep = [
        "Facility Name",
        "County_",
        "Service  Type",
        "Facility Certified",
        "Physical Address",
        "Physical Address CITY",
        "Physical Address Zipcode",
        "Total Licensed Capacity",
        "Alzheimer Capacity",
        "ICFIID Beds",
    ]
    df = df[columns_to_keep]
    # Rename columns
    df = df.rename(
        columns={
            "Facility Name": "NH_name",
            "County_": "county",
            "Service  Type": "type_of_service",
            "Facility Certified": "is_certified",
            "Physical Address": "address",
            "Physical Address CITY": "city",
            "Physical Address Zipcode": "zip",
            "Total Licensed Capacity": "total_capacity",
            "Alzheimer Capacity": "alz_capacity",
            "ICFIID Beds": "ICU_beds",
        }
    )
    # Fill na values based on zip codes
    df.loc[(df["county"].isnull()) & (df["zip"] == "78613"), "county"] = "WILLIAMSON"
    df.loc[(df["county"].isna()) & (df["zip"] == "76504"), "county"] = "BELL"
    df.loc[(df["county"].isna()) & (df["zip"] == "76802"), "county"] = "BROWN"
    # delete any characters past the first 5 letters of the zipcode
    df["zip"] = df["zip"].str[:5]
    # make zip column int
    df = df.astype({"zip": "int"})
    return df   


def create_county_fips_dataframe():
    """
    returns a dataframe with all county names and fips number
    """
    #bring in fips data
    fips = acquire_income_data()
    
    cols_to_keep = ["FIPS", "County"]
    
    #remove useless columns
    fips = fips[cols_to_keep]
    
    #lowercase the County names
    fips["County"] = fips["County"].str.lower()
    
    return fips



def create_nursing_home_counts_df():
    """
    Uses the acquire_nh_data function and creates a dataframe
    totaling the number of nursing homes per county
    """
    
    #Bring in the nursing home dataframe
    nh = acquire_nh_data()
    
    
    #Get the value counts for each county and create df
    df = pd.DataFrame(nh.county.value_counts()).reset_index()
    
    
    #Rename columns
    df.rename(columns = {"county": "num_nursing_homes"}, inplace = True)
    df.rename(columns = {"index": "County"}, inplace = True)
    
    #make county name all lower
    df["County"] = df["County"].str.lower()
    
    #sort the df counties
    df = df.sort_values(by = "County").reset_index()
    df = df.drop(columns = "index")
    
    #bring in fips df
    fips = create_county_fips_dataframe()
    
    # merge fips df with nuring home df
    fips_nh = fips.merge(df, left_on="County", right_on="County", how = "outer")
    
    return fips_nh



def acquire_covid19_cases_data():
    # read covid19 cases data
    df = pd.read_excel('./Data/Texas_COVID-19_Case_Count_Data_by_County.xlsx')
    #drop defaulted null values from excel
    df = df.dropna()
    df = df.drop(['Population'],axis=1)
    df = df.set_index('County Name')
    #transpose data
    df = df.T
    # calculate time difference
    df = df.diff()
    df = df.dropna()
    return df


def merge_dataframes():
    """
    This function creates dataframes from each csv and excel files
    in the Data folder and merges them together
    """
    # create each dataframe
    food = acquire_food_data()
    income = acquire_income_data()
    people = acquire_people_data()
    veteran = acquire_veteran_data()
    jobs = acquire_jobs_data()
    county_class = acquire_tx_county_class()
    hospital = create_hospital_count_df()
    covid = acquire_covid_cases()
    nursing = create_nursing_home_counts_df()

    # merge all dataframes into one big one
    df = food.join(income.set_index("FIPS"), on="FIPS")
    df1 = df.join(people.set_index("FIPS"), on="FIPS")
    df2 = df1.join(veteran.set_index("FIPS"), on="FIPS")
    df3 = df2.join(jobs.set_index("FIPS"), on="FIPS")
    df4 = df3.join(county_class.set_index("FIPS"), on="FIPS")
    df5 = df4.join(hospital.set_index('FIPS'), on='FIPS')
    df6 = df5.merge(covid, how = 'left', on = 'County')
    df7 = df6.merge(nursing, how = 'left', on = 'County')

    df = df7

    return df

